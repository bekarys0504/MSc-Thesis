{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bcilab02\\Documents\\beka\\thesis\\thesis-venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import signal, misc\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "data_path = r'../data/interim/dataset_1_cheb2/'\n",
    "output_path = r'../data/processed/deep_learning_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_epochs(filename, s_data, epoch_length, output_path, data_ext='.npy'):\n",
    "    start = 0\n",
    "    end = epoch_length*500\n",
    "    step = int((end-start)/2)\n",
    "    count = 0\n",
    "    while end < len(s_data):\n",
    "        if 'depressed' in filename.lower():\n",
    "\n",
    "            if data_ext == '.npy':\n",
    "                file_path = output_path+'train/Depressed/'+filename[:-4]+str(count)+data_ext\n",
    "                np.save(file_path, s_data[start:end].values.astype(np.double))\n",
    "            if data_ext == '.jpg':\n",
    "                file_path = output_path+'train_img/Depressed/'+filename[:-4]+str(count)+data_ext\n",
    "                im = Image.fromarray(s_data[start:end].values, 'L')\n",
    "                im.save(file_path)\n",
    "        elif 'healthy' in filename.lower():\n",
    "            \n",
    "            if data_ext == '.npy':\n",
    "                file_path = output_path+'train/Healthy/'+filename[:-4]+str(count)+data_ext\n",
    "                np.save(file_path, s_data[start:end].values.astype(np.double))\n",
    "            if data_ext == '.jpg':\n",
    "                file_path = output_path+'train_img/Healthy/'+filename[:-4]+str(count)+data_ext\n",
    "                im = Image.fromarray(s_data[start:end].values, 'L')\n",
    "                im.save(file_path)\n",
    "            \n",
    "        count += 1\n",
    "        start = start+step\n",
    "        end = end+step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = []\n",
    "for filename in os.listdir(data_path):\n",
    "    s_data = pd.read_csv(os.path.join(data_path, filename), index_col=False).iloc[:,2:-4]\n",
    "    length.append(len(s_data))\n",
    "    divide_into_epochs(filename, s_data, 6, output_path, '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move 200 data from train folder ot test folder\n",
    "def move_test_data(N, classname, output_path):\n",
    "    data_list = os.listdir(output_path+'train/'+classname)\n",
    "    test_data = random.sample(data_list, k=N)\n",
    "\n",
    "    for file in test_data:\n",
    "        shutil.move(output_path+'train/'+classname+'/'+file, output_path+'test/'+classname+'/'+file)\n",
    "\n",
    "move_test_data(500, 'Depressed', output_path)\n",
    "move_test_data(500, 'Healthy', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follwing classes are there : \n",
      " ['Depressed', 'Healthy']\n",
      "Length of Train Data : 13905\n",
      "Length of Validation Data : 2000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_default_device()\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "\n",
    "#train and test data directory\n",
    "data_dir = output_path+\"train_img/\"\n",
    "test_data_dir = output_path+\"test_img/\"\n",
    "\n",
    "def npy_loader(path):\n",
    "    sample = torch.from_numpy(np.load(path))\n",
    "    return sample\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "#load the train and test data\n",
    "dataset = ImageFolder(\n",
    "    root=data_dir,transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    ")\n",
    "test_dataset = ImageFolder(\n",
    "    root=test_data_dir,transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    ")\n",
    "\n",
    "img, label = dataset[0]\n",
    "\n",
    "print(\"Follwing classes are there : \\n\",dataset.classes)\n",
    "\n",
    "\n",
    "def display_img(img,label):\n",
    "    print(f\"Label : {dataset.classes[label]}\")\n",
    "    plt.imshow(img.permute(0,2))\n",
    "\n",
    "#display the first image in the dataset\n",
    "#display_img(*dataset[0])\n",
    "\n",
    "batch_size = 32\n",
    "val_size = 2000\n",
    "train_size = len(dataset) - val_size \n",
    "\n",
    "train_data,val_data = random_split(dataset,[train_size,val_size])\n",
    "print(f\"Length of Train Data : {len(train_data)}\")\n",
    "print(f\"Length of Validation Data : {len(val_data)}\")\n",
    "\n",
    "#output\n",
    "#Length of Train Data : 12034\n",
    "#Length of Validation Data : 2000\n",
    "\n",
    "#load the train and validation into batches.\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle = True, num_workers = 4)\n",
    "val_loader = DataLoader(val_data, batch_size, num_workers = 4)\n",
    "\n",
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        images = torch.reshape(images, (-1, 1, 500, 31))\n",
    "        out = self(images.double())                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        images = torch.reshape(images, (-1, 1, 500, 31))\n",
    "        out = self(images.double())                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 0.7109, val_loss: 0.9294, val_acc: 0.4816\n",
      "Epoch [1], train_loss: 0.6735, val_loss: 0.6839, val_acc: 0.5565\n",
      "Epoch [2], train_loss: 0.6787, val_loss: 0.6911, val_acc: 0.5446\n",
      "Epoch [3], train_loss: 0.6770, val_loss: 2.6132, val_acc: 0.4633\n",
      "Epoch [4], train_loss: 0.6753, val_loss: 0.6822, val_acc: 0.5565\n",
      "Epoch [5], train_loss: 0.6739, val_loss: 0.6857, val_acc: 0.5491\n",
      "Epoch [6], train_loss: 0.6738, val_loss: 1.9667, val_acc: 0.4836\n",
      "Epoch [7], train_loss: 0.6761, val_loss: 1.6526, val_acc: 0.4742\n",
      "Epoch [8], train_loss: 0.6739, val_loss: 0.6841, val_acc: 0.5129\n",
      "Epoch [9], train_loss: 0.6746, val_loss: 0.6798, val_acc: 0.5565\n",
      "Epoch [10], train_loss: 0.6739, val_loss: 0.6855, val_acc: 0.5565\n",
      "Epoch [11], train_loss: 0.6744, val_loss: 0.6789, val_acc: 0.5565\n",
      "Epoch [12], train_loss: 0.6760, val_loss: 0.6807, val_acc: 0.5541\n",
      "Epoch [13], train_loss: 0.6744, val_loss: 0.7218, val_acc: 0.5446\n",
      "Epoch [14], train_loss: 0.6742, val_loss: 0.6745, val_acc: 0.5689\n",
      "Epoch [15], train_loss: 0.6751, val_loss: 0.7405, val_acc: 0.5565\n",
      "Epoch [16], train_loss: 0.6762, val_loss: 0.6900, val_acc: 0.5565\n",
      "Epoch [17], train_loss: 0.6761, val_loss: 0.6743, val_acc: 0.5580\n",
      "Epoch [18], train_loss: 0.6782, val_loss: 0.6858, val_acc: 0.5565\n",
      "Epoch [19], train_loss: 0.6742, val_loss: 0.6844, val_acc: 0.5412\n",
      "Epoch [20], train_loss: 0.6756, val_loss: 0.6785, val_acc: 0.5327\n",
      "Epoch [21], train_loss: 0.6722, val_loss: 0.6772, val_acc: 0.5496\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 85\u001b[0m\n\u001b[0;32m     83\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     84\u001b[0m \u001b[39m#fitting the model on training data and record the result after each epoch\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m history \u001b[39m=\u001b[39m fit(num_epochs, lr, model, train_loader, val_loader, opt_func)\n",
      "Cell \u001b[1;32mIn [9], line 65\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[0;32m     63\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     64\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 65\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     66\u001b[0m     loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     67\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(loss)\n",
      "Cell \u001b[1;32mIn [2], line 33\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl: \n\u001b[1;32m---> 33\u001b[0m     \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n",
      "Cell \u001b[1;32mIn [2], line 21\u001b[0m, in \u001b[0;36mto_device\u001b[1;34m(data, device)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39m\"\"\"Move tensor(s) to chosen device\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (\u001b[39mlist\u001b[39m,\u001b[39mtuple\u001b[39m)):\n\u001b[1;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m [to_device(x, device) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n\u001b[0;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [2], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39m\"\"\"Move tensor(s) to chosen device\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (\u001b[39mlist\u001b[39m,\u001b[39mtuple\u001b[39m)):\n\u001b[1;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m [to_device(x, device) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n\u001b[0;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [2], line 22\u001b[0m, in \u001b[0;36mto_device\u001b[1;34m(data, device)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (\u001b[39mlist\u001b[39m,\u001b[39mtuple\u001b[39m)):\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m [to_device(x, device) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n\u001b[1;32m---> 22\u001b[0m \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39;49mto(device, non_blocking\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class EEGClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 16, kernel_size = (16,13), padding = 'same'),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.AvgPool2d((6,6), padding=2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size = (12,5), padding = 'same'),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.AvgPool2d((2,2)),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size = (10,1), padding = 'same'),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.AvgPool2d((2,2)),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size = (8,1), padding = 'same'),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.AvgPool2d((2,1)),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size = (6,1), padding = 'same'),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2560,1024),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(1024,2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.double()\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history\n",
    "\n",
    "num_epochs = 50\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001\n",
    "model = EEGClassification()\n",
    "model.to(device)\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_loader, val_loader, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "# import warnings\n",
    "# from sys import platform\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "from tensorflow import keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7522478740914477701\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14582884875788460239\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\bcilab02\\Documents\\beka\\thesis\\MSc-Thesis\\data\\processed\\deep_learning_data\\train\\Depressed/'\n",
    "X = []\n",
    "labels = []\n",
    "for i in os.listdir(path):\n",
    "    data = np.load(path+i)\n",
    "    X.append(data)\n",
    "    labels.append(0)\n",
    "\n",
    "path = r'C:\\Users\\bcilab02\\Documents\\beka\\thesis\\MSc-Thesis\\data\\processed\\deep_learning_data\\train\\Healthy/'\n",
    "for i in os.listdir(path):\n",
    "    data = np.load(path+i)\n",
    "    X.append(data)\n",
    "    labels.append(1)\n",
    "\n",
    "kernels, chans, samples = 1, 31, 500\n",
    "y = labels\n",
    "temp = list(zip(X, y))\n",
    "random.shuffle(temp)\n",
    "X, y = zip(*temp)\n",
    "# res1 and res2 come out as tuples, and so must be converted to lists.\n",
    "X, y = list(X), list(y)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X = X[..., np.newaxis]\n",
    "# take 50/25/25 percent of the data to train/validate/test\n",
    "X_train      = X[0:1500,]\n",
    "Y_train      = y[0:1500]\n",
    "X_validate   = X[1500:,]\n",
    "Y_validate   = y[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 3000, 31, 16)      3344      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 3000, 31, 16)     64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 500, 5, 16)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 500, 5, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 500, 5, 32)        30752     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 500, 5, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 125, 1, 32)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 125, 1, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 125, 1, 64)        20544     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 125, 1, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 41, 1, 64)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 41, 1, 64)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 41, 1, 128)        65664     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 41, 1, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 20, 1, 128)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 20, 1, 128)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 20, 1, 256)        196864    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 20, 1, 256)       1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 10, 1, 256)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 10, 1, 256)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2560)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 5122      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,274\n",
      "Trainable params: 323,282\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "75/75 [==============================] - 172s 2s/step - loss: 1.0540 - accuracy: 0.5507 - val_loss: 1.7273 - val_accuracy: 0.5409\n",
      "Epoch 2/200\n",
      "74/75 [============================>.] - ETA: 2s - loss: 0.7714 - accuracy: 0.6270"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 50\u001b[0m\n\u001b[0;32m     42\u001b[0m optimizer \u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mlr_schedule)\n\u001b[0;32m     44\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[0;32m     45\u001b[0m               loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m     46\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     47\u001b[0m               )\n\u001b[1;32m---> 50\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train,Y_train,\n\u001b[0;32m     51\u001b[0m                     epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[0;32m     52\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(X_validate,Y_validate),\n\u001b[0;32m     53\u001b[0m                     batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE,\n\u001b[0;32m     54\u001b[0m                     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     57\u001b[0m train_predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x \u001b[39m=\u001b[39m X_train)\n\u001b[0;32m     58\u001b[0m \u001b[39mprint\u001b[39m(train_predictions)\n",
      "File \u001b[1;32mc:\\Users\\bcilab02\\Documents\\beka\\thesis\\thesis-venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bcilab02\\Documents\\beka\\thesis\\thesis-venv\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\bcilab02\\Documents\\beka\\thesis\\thesis-venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bcilab02\\Documents\\beka\\thesis\\thesis-venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\bcilab02\\Documents\\beka\\thesis\\thesis-venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\bcilab02\\Documents\\beka\\thesis\\thesis-venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\bcilab02\\Documents\\beka\\thesis\\thesis-venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\bcilab02\\Documents\\beka\\thesis\\thesis-venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\bcilab02\\Documents\\beka\\thesis\\thesis-venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Conv2D(16,(16,13),activation='elu',input_shape=(3000,31,1), padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.AveragePooling2D((6,6)))\n",
    "model.add(layers.Dropout(rate=0.25))\n",
    "\n",
    "model.add(layers.Conv2D(32,(12,5), activation='elu', padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.AveragePooling2D((4,4)))\n",
    "model.add(layers.Dropout(rate=0.25))\n",
    "\n",
    "model.add(layers.Conv2D(64,(10,1), activation='elu', padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.AveragePooling2D((3,1)))\n",
    "model.add(layers.Dropout(rate=0.25))\n",
    "\n",
    "model.add(layers.Conv2D(128,(8,1), activation='elu', padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.AveragePooling2D((2 ,1)))\n",
    "model.add(layers.Dropout(rate=0.25))\n",
    "\n",
    "model.add(layers.Conv2D(256,(6,1), activation='elu', padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.AveragePooling2D((2,1)))\n",
    "model.add(layers.Dropout(rate=0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "#model.add(layers.Dense(50, activation='elu'))\n",
    "model.add(layers.Dense(2))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 20\n",
    "step_per_epoch = math.ceil(X_train.shape[0]/BATCH_SIZE)\n",
    "STEP_TOTAL = step_per_epoch * EPOCHS\n",
    "INIT_LEARNING_RATE =  0.001\n",
    "\n",
    "lr_schedule=CosineDecay(INIT_LEARNING_RATE,STEP_TOTAL,\n",
    "                                                      alpha=0.0,\n",
    "                                                      name=None)\n",
    "optimizer =Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "\n",
    "history = model.fit(X_train,Y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_validate,Y_validate),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=True)\n",
    "\n",
    "\n",
    "train_predictions = model.predict(x = X_train)\n",
    "print(train_predictions)\n",
    "\n",
    "\n",
    "test_predictions = model.predict(x = X_validate)\n",
    "print(test_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('thesis-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "082a3e3abd536aae1f81a4133a9551c048ac1856ca8ae3398f27debf6dcca2d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
