{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal, misc\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "data_path = r'../data/interim/dataset_1_cheb2/'\n",
    "output_path = r'../data/processed/deep_learning_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_epochs(filename, s_data, output_path):\n",
    "    start = 0\n",
    "    end = 2000\n",
    "    step = int((end-start)/2)\n",
    "    count = 0\n",
    "    while end < len(s_data):\n",
    "        if 'depressed' in filename.lower():\n",
    "            npy_path = output_path+'train/Depressed/'+filename[:-4]+str(count)+'.jpeg' #remove .csv from filename and append count and .txt extension\n",
    "            im = Image.fromarray(s_data[start:end].values)\n",
    "            if im.mode != 'RGB':\n",
    "                im = im.convert('RGB')\n",
    "            im.save(npy_path)\n",
    "            #np.save(npy_path, s_data[start:end].values.astype(np.double))\n",
    "        elif 'healthy' in filename.lower():\n",
    "            npy_path = output_path+'train/Healthy/'+filename[:-4]+str(count)+'.jpeg'\n",
    "            im = Image.fromarray(s_data[start:end].values)\n",
    "            if im.mode != 'RGB':\n",
    "                im = im.convert('RGB')\n",
    "            im.save(npy_path)\n",
    "            #np.save(npy_path, s_data[start:end].values.astype(np.double))\n",
    "        count += 1\n",
    "        start = start+step\n",
    "        end = end+step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot write mode F as JPEG",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Downloads\\DTU\\semester 4\\thesis\\thesis_venv\\lib\\site-packages\\PIL\\JpegImagePlugin.py:630\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 630\u001b[0m     rawmode \u001b[39m=\u001b[39m RAWMODE[im\u001b[39m.\u001b[39;49mmode]\n\u001b[0;32m    631\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'F'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32md:\\Downloads\\DTU\\semester 4\\thesis\\MSc-Thesis\\notebooks\\deep_learning.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Downloads/DTU/semester%204/thesis/MSc-Thesis/notebooks/deep_learning.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m s_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_path, filename), index_col\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39miloc[:,\u001b[39m2\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Downloads/DTU/semester%204/thesis/MSc-Thesis/notebooks/deep_learning.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m length\u001b[39m.\u001b[39mappend(\u001b[39mlen\u001b[39m(s_data))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Downloads/DTU/semester%204/thesis/MSc-Thesis/notebooks/deep_learning.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m divide_into_epochs(filename, s_data, output_path)\n",
      "\u001b[1;32md:\\Downloads\\DTU\\semester 4\\thesis\\MSc-Thesis\\notebooks\\deep_learning.ipynb Cell 3\u001b[0m in \u001b[0;36mdivide_into_epochs\u001b[1;34m(filename, s_data, output_path)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Downloads/DTU/semester%204/thesis/MSc-Thesis/notebooks/deep_learning.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     npy_path \u001b[39m=\u001b[39m output_path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain/Healthy/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mfilename[:\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m]\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(count)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.jpeg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Downloads/DTU/semester%204/thesis/MSc-Thesis/notebooks/deep_learning.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     im \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(s_data[start:end]\u001b[39m.\u001b[39mvalues)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Downloads/DTU/semester%204/thesis/MSc-Thesis/notebooks/deep_learning.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     im\u001b[39m.\u001b[39;49msave(npy_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Downloads/DTU/semester%204/thesis/MSc-Thesis/notebooks/deep_learning.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m#np.save(npy_path, s_data[start:end].values.astype(np.double))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Downloads/DTU/semester%204/thesis/MSc-Thesis/notebooks/deep_learning.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32md:\\Downloads\\DTU\\semester 4\\thesis\\thesis_venv\\lib\\site-packages\\PIL\\Image.py:2320\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2317\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mw+b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2319\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2320\u001b[0m     save_handler(\u001b[39mself\u001b[39;49m, fp, filename)\n\u001b[0;32m   2321\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   2322\u001b[0m     \u001b[39mif\u001b[39;00m open_fp:\n",
      "File \u001b[1;32md:\\Downloads\\DTU\\semester 4\\thesis\\thesis_venv\\lib\\site-packages\\PIL\\JpegImagePlugin.py:632\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename)\u001b[0m\n\u001b[0;32m    630\u001b[0m     rawmode \u001b[39m=\u001b[39m RAWMODE[im\u001b[39m.\u001b[39mmode]\n\u001b[0;32m    631\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 632\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot write mode \u001b[39m\u001b[39m{\u001b[39;00mim\u001b[39m.\u001b[39mmode\u001b[39m}\u001b[39;00m\u001b[39m as JPEG\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    634\u001b[0m info \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mencoderinfo\n\u001b[0;32m    636\u001b[0m dpi \u001b[39m=\u001b[39m [\u001b[39mround\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m info\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdpi\u001b[39m\u001b[39m\"\u001b[39m, (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m))]\n",
      "\u001b[1;31mOSError\u001b[0m: cannot write mode F as JPEG"
     ]
    }
   ],
   "source": [
    "length = []\n",
    "for filename in os.listdir(data_path):\n",
    "    s_data = pd.read_csv(os.path.join(data_path, filename), index_col=False).iloc[:,2:-4]\n",
    "    length.append(len(s_data))\n",
    "    divide_into_epochs(filename, s_data, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move 200 data from train folder ot test folder\n",
    "def move_test_data(N, classname, output_path):\n",
    "    data_list = os.listdir(output_path+'train/'+classname)\n",
    "    test_data = random.sample(data_list, k=N)\n",
    "\n",
    "    for file in test_data:\n",
    "        shutil.move(output_path+'train/'+classname+'/'+file, output_path+'test/'+classname+'/'+file)\n",
    "\n",
    "move_test_data(400, 'Depressed', output_path)\n",
    "move_test_data(400, 'Healthy', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 31]) 0\n",
      "Follwing classes are there : \n",
      " ['Depressed', 'Healthy']\n",
      "Label : Depressed\n",
      "Length of Train Data : 3243\n",
      "Length of Validation Data : 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAE4AAAGiCAYAAABJW/BQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnB0lEQVR4nO2de5BcZZ33P89zLn2ZS09mcp2QDBDWCJLAiiSbWg1SREKk3LVkL1zWRI1RrEQXUCpvfJW7CRJFXFdxt0pwtxYvSy0qFV3eJQFhlYhUqHA33IIBTEJuc+np6T6X5/f+cTod2kzImclJmBzPp6or06fPefr0N885z3Oe5/n+fkpEhIwRo9/uEzheyYQbJZlwoyQTbpRkwo2STLhRkgk3SjLhRkkm3CjJhBslY1q4b3/725x44onk83nmzp3Lb3/727f7lA4gY5Qf/ehH4rqu3HHHHfLMM8/IsmXLpKOjQ3bu3Pl2n5qIiIxZ4ebMmSPLly9vvA/DULq7u2XNmjVv41kdwH67a/xweJ7Hpk2bWLVqVWOb1poFCxawcePGYY+p1WrUarXGe2MMe/fupaurC6VUY7uIMDAwQHd3N1qP/k41JoXbvXs3YRgyadKkpu2TJk3id7/73bDHrFmzhuuvvz72d7z66quccMIJoz7HMSncaFi1ahVXXXVV431fXx/Tp09n2jVfQhXyiCWILTDg8dq1N9HW1nZE3zcmhRs/fjyWZbFz586m7Tt37mTy5MnDHpPL5cjlcgdtd4Ii6Bxhi4E2H2nzAZou39EwJrsjruty1llnsWHDhsY2YwwbNmxg3rx5IypLB6AAFOSKPuM6Komc45iscQBXXXUVS5Ys4T3veQ9z5szhtttuY3BwkI9//OMjKsfYII4grqGYrzFelxM5vzEr3N///d+za9currnmGnbs2MGZZ57Jfffdd1CDcThMThA3mlbxAhvPshI5vzErHMCKFStYsWLFEZURlEJ0IQQNvm+xzyskcm5jWrgk0EUfZTuIgFd1qFZakik3kVLGMHYuQDsGpQUp2zivH9zyjobUC+c4Bq0j4XRV4/QdWTdkP6m/VF07wHJ9gsCi2mYTJlPh0i9c795WVD6P0gIGjJPMwoXUC6d3u6g2B5M36FYff5qXSLmpF87pU4itMC6U2itM7drBqwmUm/rGQQegPYXyNV5g0+5UEyk39TWuNt7AuBBafQquj61MIuWmXrhwXIDVptG2oTyU49mh4UdXRkrqhXNbamDbmFBRreao9I1LpNzUCzepVKZiaaqew1Cg0dVkbuupF24ocKiGDrUhB6oWdjm7x8Vi9452tFtABRprSKG97JErFla/jc5biAbjCtKSPTnEQtcU5MDkDLrNR7cnMwKc+g6wVVHoQIGGXMHn5Al7Eyk39TUubBVMQVD5kJwT4OogkXLTL1xewDHga8qDebYOdiVSbuqFkw4vahwCRTBk4/W3JlJu6u9xTi5AWQZChe63yf8hmbqSeuG0ZRBRYBTWkMLtT6bc1F+qpWKVMnmqAoGnsYrJlJt64XbtaQMrD55GKSEoZh3gWOideWi1EUeg5GOKQ8mUm0gpYxh7QGHVog5wsa3GaVO3J1NuIqWMYdx+MLZCLM3QoEuvTmYJROprnLFB6utsjG+xt5JM65D6Gue3gnYFBFTZojyQzNqR1AvndYXYlqAChV3WWINZBzgWquQRFg1iC/aQIrcvG8iMhZ0LCFVAiE3gKezeZMpNfY3zh1zEKLCFoM0QJHOLS3+Nc153US0uYkULbsTKnhxi4fQrEEVYrNe4CckMZCZ+qa5Zs4azzz6btrY2Jk6cyIc//GG2bNnStM/73/9+lFJNr8svv7xpn23btnHhhRdSLBaZOHEiV199NUEw8h9tVetL9kNAwG71j+TnNUi8xj300EMsX76cs88+myAI+OIXv8j555/Ps88+S0vLgRvMsmXLuOGGGxrvi8UDHdMwDLnwwguZPHkyjzzyCNu3b2fx4sU4jsPq1atHdD5BCygXJOEqkrhw9913X9P773//+0ycOJFNmzYxf/78xvZisXhIl8z//M//8Oyzz7J+/XomTZrEmWeeyY033sjKlSu57rrrcF039vnUxht03kQLCm3BmGS6I0e9Ve3r6wOgs7Ozaftdd93F+PHjOf3001m1ahWVygHHy8aNG5k1a1aTp2HhwoX09/fzzDPPDPs9tVqN/v7+phdEDYKxAQ1qyEL64ov+VhzVxsEYwxVXXMFf/uVfcvrppze2X3rppfT09NDd3c2TTz7JypUr2bJlC/fccw8AO3bsGNY5uP+z4Tike7DdR1wHAoWqaqzB42DtyPLly3n66af51a9+1bT9U5/6VOPvWbNmMWXKFM477zxeeuklZsyYMarv+mP3YH9/P9OmTaPQ6iGuhe/ZGONgJdOoHr1LdcWKFaxbt44HH3zwsL7QuXPnAvDiiy8CMHny5GGdg/s/G45cLkd7e3vTC0AElIpemGiCOgkSF05EWLFiBT/5yU944IEHOOmkkw57zObNmwGYMmUKAPPmzeOpp57ijTfeaOxz//33097ezmmnnTai8xnaV6Damyfsd9CexjgjOvyQJH6pLl++nB/84Af87Gc/o62trXFPKpVKFAoFXnrpJX7wgx/wwQ9+kK6uLp588kmuvPJK5s+fz+zZswE4//zzOe200/joRz/KLbfcwo4dO/jSl77E8uXLh/WkvhXuThtKNmIJYdEQnJDMqvPEgxkAw77uvPNOERHZtm2bzJ8/Xzo7OyWXy8kpp5wiV199tfT19TWV88orr8iiRYukUCjI+PHj5fOf/7z4vh/7PPr6+gSQP/vCapnx1a9Lz7fWyowf3SjnrrtcgIO+b6QkXuPkMJEjp02bxkMPPXTYcnp6evjFL35xxOcTutEIsLhCLu/TlU/G6Jv60RHsAw/2vm+xp5oNncciKArkDdjRjH7FPw46wGMB0xag8zYI+DWbN8pHFv1hP6kXrrWzgrgQ+BZGFEFCcw6pF66Ur6KLEIoiCC32Vo6DR66xwN7BItrkEVGEgSYYyEaAYzG0q4gu5KPgI44BNzPBxcLdZaNbLYwDQYeQa60d/qAYpL4fp0w0+mscQeVCJpUGEik39TVOHEFsEFuwHEPRGaNzDmONsCDgCuIIoWexvb89kXLTL1x7gM6FAEjVoi+h1Uqpv8dZ+RBdCKIWFbD2JTMgl/4aV7XQ2oJQoWoaazBbdBMLPWCjg+hZVfsKdbxMD77daE9Fggmo/cOqCZD6GmdXFBoVzTUImIQW3aS+xiGAidaOiA1+R2Ytj4WxQYqCsSP7pZXLHrnioQXR9ZXnQmJrR1Jf48I8aC2oELSnCfqTiYOWeuGMa8CVejdEsIayGhcLFUbdEQRUoFDVTLhYWJ5CaYUiighhJ+RXTX/jINRDT4NYgkkmDHD6a5wK608MRF2ToCvrAMdCBQpVXxMnthCMy8JnxCJoM6hitAxCXMFNqAOceuHEIlr/GyrUkMKrZv24WJi2AG2H4GmsIY2TzeTHxNNoz8IuK9x+BVnk6XjomsYyCruisCugy9lMfix0LRqPQwGRrSsRUi+c069wrPp4nCaxDljqhbOHQOfqnd8CGMbonMN11113kDPwne98Z+PzarXK8uXL6erqorW1lYsuuuggT0NSzkEAY4FxIMyB3yoMTR7DI8Dvete7WL9+/YEvsQ98zZVXXsnPf/5z7r77bkqlEitWrOAjH/kIv/71r4FknYMQjcdJEUJXovw1xWSWQCS+XP/aa6+VM844Y9jPent7xXEcufvuuxvbnnvuOQFk48aNIiLyi1/8QrTWsmPHjsY+t99+u7S3t0utVot9Ho3l+p9fLTOvuVXecf2t8o7rbpWe1Tclslz/qDyrvvDCC3R3d3PyySdz2WWXsW3bNgA2bdqE7/ssWLCgse873/lOpk+f3sgpOBrnIBzaPagErBq4vVDcLpSeH6P3uLlz5/L973+f++67j9tvv52tW7fyvve9j4GBAXbs2IHrunR0dDQdM2nSpIYDZzTOQYjcg6VSqfGaNm0aEDUKGLCHhMIeQ8eWZIJSJX6PW7RoUePv2bNnM3fuXHp6evjP//xPCoVk4hoNx6Hcg2FRMD4EeUXoKlxznAwrdXR08I53vIMXX3yRyZMn43kevb29Tfu8OafgaJyDcGj3oDJgXAiKUCspauOOkyxJ5XKZl156iSlTpnDWWWfhOE5TTsEtW7awbdu2Rk7BJJ2DAITR04LJQW2cor9njD7kf+ELX+BDH/oQPT09/OEPf+Daa6/FsiwuueQSSqUSS5cu5aqrrqKzs5P29nY++9nPMm/ePP7iL/4CSNY5CPXsIQ4YW/A7ISiN0X7ca6+9xiWXXMKePXuYMGEC733ve/nNb37DhAkTAPjGN76B1pqLLrqIWq3GwoUL+c53vtM43rIs1q1bx2c+8xnmzZtHS0sLS5YsaYoYMSJUNNeAjkaASSh8hhI5jN3vOKW/v59SqUTPTV9BF3NgFMYVTK6fVz99A319fY374GhI/bNqWAxRFugQ7EFFUM5McPFQ0X3OriicfpByZkmKhQoV2gNrCHK9gv1GmEi5qZ8eFC0YJxohUSHYQ5lwsVBvGvIVDZY3RrsjYw09pNEakGhMLnT/BFIhJ4EO6wOZHYLfBpUWB9Yf/rjDkXrhVACoKGeN5AxeLlsCEYvGBI0GXIOlMxNcPFTUmuqawiib0MssSbFQQeR1UEZFU4SVMTo6MtYIWgWFRDP5Q6D6jpOBzLcbkzdRBjgLtAfuYLYEIhYqiNY+iBbEVklZudIv3P6uiG9FeaRVLnvIj4Wzx0IXNWgICkJwQtYdiYUyRLXOAdMa0tY6mEi5qRfO5AUKgnGj/INFN5mIhakXLuoAK5QPpmrRRz6RYlMvXJgTbCKHjd5n45lkcg+mXjhTDDFGcAYUTlmh9iXTqqa+A+y01TAFQ5iLIu0XdmUjwPEQBZZgHCEoQJj14+LhD7poWyEWeCUhmJot14+Fu8uGFgvjCn5HiGnLuiOxyO1WGBS+BmkNOLnjDV5LoNw/gXtc/R9LsGxDZ0IBlFNf48I8jdl8v9/lBTUhkXJTL5xYoA1RqtC9Fv0DWfy4WFQnhliuaawfye9OZl419fc4Z1IFGecTthhUCLmEhs5TX+PaW2pU8KiGirCgsVXWj4tF/2AO6sseTIK/NvWXqtefJxiKFAtKIZUTsks1FnavDaGNuILkQ/yJ2ZNDLOwBhSIyh4QCKqGALYlfqieeeOJBtkulFMuXLweObcJGiCak/dYo0Y8UQiwnmWGlxGvcY489RhgeOLmnn36aD3zgA/zt3/5tY9uxStgI0WSNChRGgXgao8doq7rfz7Cfm2++mRkzZnDOOec0th2NhI21Wo1a7UAwlv3uQV2NDCJRxBuLQCWz6vyotqqe5/Ef//EffOITn0C9qf+UdMJGOLR70OsK8UuGoEUweXN8RGX96U9/Sm9vLx/72Mca245GwkY4tHvQmVhB5QUxmqBmwfEQQPl73/seixYtoru7u7HtaCRshMg9OJzXS0KN64RoHeBZNtX8GF+t9Pvf/57169fzyU9+8i33SyJh41vh9+UYGsjjeTbtLVWmTNs74jKG46gJd+eddzJx4kQuvPDCt9zvaCZsBHD3Wqh9Dl5fjsGqy7jCGHVIQ5SQ9s4772TJkiVNESCOdcJGiAK2GEcTBIohO0/ZHsNervXr17Nt2zY+8YlPNG13XZf169dz2223MTg4yLRp07jooov40pe+1NgnadulWFFAAx1A6Gn2JZTPIfW2y5Ou+wqqkAcNYdFAvo/fL70ps10ejjAvWLZEi28CRXA8JN8eE3TVCG07Sr7ta3SWCS4e48eVqTlQGYzSIdsJ5ZBOvXDlWg6l6i2EJVHWpARIvXDeS23QnkNcQbX55HrKiZSb+qFze0BhDSnEEro6yyzseS6ZchMpZQxj3CgBhioGtOZqTHSSSaGX+hq33wTHgMNru8bx/3aemkixqa9xfpugcwIGgj6XV3ZOOvxBMUi9cOJEg5dWVeP0KfSezD0YCyUKq6JxBhRtrwq515KZHkz9PU60HPiVAk5/Nq8aC3vAwlJg1S1cktDakdTXOKuiGgl+vHZF+cRkoiamX7j6jKHfKvT/mWHn/GSiQKRfOO9NeaTbAiZ370uk3NTf40IXlFMPo+FrakHWHYmF1ymoFhMJp4SBgWTucakXzriCtkD5CqvfxniZ7TIWxjEoBVYYzXjRl40Ax6MQIlZIGFrkPEXhjWTCoKW+VQUgVOggCthiD2bx4+LhaTQaFUYRqL22LH5cLHTFimyXGoYmCAOdyZSbeuGcfo0uRDGAg5IhV0pmBDj1wmkPLF3vAAsolc1yxSJoFUw+ijsituD7WXckFkGLQecFdPTyylnuwXh0+IjtgK8hUFi9yfzkP41+XL22WUOawvbsUo3HgINyHHQA7j5Nfm/WOMTC2WNhuzpKTKuhfEK26CYWThlUa5SzxhsfoorJBDNI/T0uKILfLvjtgj2hyukn/CGRclNf40xBMC0GaQ1pax1iWiGZofMR17iHH36YD33oQ3R3d6OU4qc//WnT5yLCNddcw5QpUygUCixYsIAXXnihaZ+9e/dy2WWX0d7eTkdHB0uXLqVcbl5+9eSTT/K+972PfD7PtGnTuOWWW0b+69gfPFmjBi16+1rY+MZJoyrnjxmxcIODg5xxxhl8+9vfHvbzW265hX/6p3/iu9/9Lo8++igtLS0sXLiQarXa2Oeyyy7jmWee4f7772fdunU8/PDDTY6b/v5+zj//fHp6eti0aRNr167luuuu41//9V9H8ROjCRunX6Nfz9P7bNeoyjiII0lcCMhPfvKTxntjjEyePFnWrl3b2Nbb2yu5XE5++MMfiojIs88+K4A89thjjX3++7//W5RS8vrrr4uIyHe+8x0ZN25cU5LGlStXysyZM2Of2/6kjdO/epPM+OrX5c9uuFVO/T+3yuwlXxl7SRu3bt3Kjh07mpIylkol5s6d25SUsaOjg/e85z2NfRYsWIDWmkcffbSxz/z585sslgsXLmTLli3s2zf8PepQSRuFevpjJVg1KOwZg/Hj9rv7hnP/vTkp48SJE5s+t22bzs7OI0rceCjbpdOnsYcUKojG5IJ8FrGwiVWrVtHX19d4vfrqqwDk9oGuRQ6boYnCnjPGYAd4v7tv586dDVPb/vdnnnlmY583G9wAgiBg7969R5S48VC2S1Q0ZO63G6wpFU5pe51XRvPj/ohEa9xJJ53E5MmTm5Iy9vf38+ijjzYlZezt7WXTpk2NfR544AGMMQ0L5rx583j44Yfx/QNRou+//35mzpzJuHHjRnROUYYkQRyhpeAxo3X3kfzEBiMWrlwus3nz5oZdcuvWrWzevJlt27ahlOKKK67gpptu4t577+Wpp55i8eLFdHd38+EPfxiAU089lQsuuIBly5bx29/+ll//+tesWLGCiy++uGEIvvTSS3Fdl6VLl/LMM8/w4x//mG9+85tNDui4GDsa/VWBojyY56Xy+BGXMSwjbYYffPBBod5Yvfm1ZMkSEYm6JF/+8pdl0qRJksvl5LzzzpMtW7Y0lbFnzx655JJLpLW1Vdrb2+XjH/+4DAwMNO3zxBNPyHvf+17J5XIydepUufnmm0d0nvu7IzNWrZZTVn9dTl77dZl++y1y0p1fTKQ7knr34AnfuAFdOLDswVSrvHbFNUfsHkxNq3oorHYP1RKALShP4/Rm8eNi4eYCLNvUR4AV+V3ZUtZY5JwAyw5R9eS0TpZ6JR79fQVUzkUCRZgTvNasxsXClB2kaoECxnmUZ2YZRGLh9FkgGlNQ6HxIYXwyGURSX+NUADpQKF8R1iyMyaYHYyH1X6g9hQzYVJxsJj8WxgFtS7SwsFLP+pMA6RfONSgbCMAaUqiEokCk/x7X4UVp9CzqAZSTKTf1Nc7JB4TaJxQwFRsdjPEwaGMFEVCWoAohfpvB2GNwBHgs4lVcdGijLMG0hgxNyh654uFrcEE7hkJpCGmtHv6YGKReOF2xUNoiBHzHopSrHfaYOKRfOE+hqhpjFDVR7HOTiR+XeuFQoEOwygqp2PiqJZFiUy+ccQWtoudVywPlZc+qsTCuQcIomJc9BE5v1qrGwxJECcYB0QonmaCsfwLCCYgrBCr6W/VmHeBYWGUL1RqFQfM6DTU786vGQyLRJG9wOqt0zUgm8nTqa5xdVoijCY0iyNlIPrtUY2FXQFmKwAdfOwyYLJxtLMICUVoCG3RN4QVZ+IxYBEVBu/WgrEMKVclMcLEI84LJSZS8MYwCGiRB6mscOvJwYepu6WQcSemvcWJFlkuJ5qWxatnQeSzssoWuRj8zLAi19qw7Egt7UCEOhEXBn+ATTskiT8dCdDSbbwohpXGDnJG5B+MhtkQBRo1icMilTycTzStR96Dv+6xcuZJZs2bR0tJCd3c3ixcv5g9/aP5fHi4/4c0339y0T1LuwSgGsMLpswh2Ftm6M5lV54m6ByuVCo8//jhf/vKXefzxx7nnnnvYsmULf/VXf3XQvjfccAPbt29vvD772c82PkvSPahrCmdAkdutaHldY73wNs05LFq0iEWLFg37WalU4v7772/a9s///M/MmTOHbdu2MX369Mb2tra2Q7pk7rrrLjzP44477sB1Xd71rnexefNmbr311iZ7ZhxMQQhVNPprV0AlMzt49BuHvr4+lFJ0dHQ0bb/55pvp6uriz//8z1m7dm1TGtAk3YNhXiJnjQarKuT3HQdh0KrVKitXruSSSy5p8hR87nOf493vfjednZ088sgjrFq1iu3bt3PrrbcCkUPwpJOancxvdg8OZ0tas2YN119//UHbw4JBESX7sYcU+V1jfM7B933+7u/+DhHh9ttvb/rszdai2bNn47oun/70p1mzZs2okpbBoZM2YgkmZ/BzCkTjbh/DHeD9ov3+97/ngQceOKyDZe7cuQRBwCuvvMLMmTMTdQ/a+2xUq8bkokgQAyeM0fVx+0V74YUXWL9+PV1dh/fAb968Ga11wwCcpHtQh0TD57ZgTaiiz+4d0fGHYsQ1rlwuNzJTwgH3YGdnJ1OmTOFv/uZvePzxx1m3bh1hGDYczZ2dnbiuy8aNG3n00Uc599xzaWtrY+PGjVx55ZX8wz/8Q0OUSy+9lOuvv56lS5eycuVKnn76ab75zW/yjW98Y8Q/UOoOJBUotGWY3tbL70ZcynAFj5C3cg9u3bp12M8AefDBB0VEZNOmTTJ37lwplUqSz+fl1FNPldWrV0u1Wm36nqTcg6esXC3vuO5WmfHVr8v0790sc3/yucw9+Fbsdw/O+D+rsXJ5jCP4HQantIcXP3pzlnvwcIQFQdmC9hW5PRa13rZEyk29cEEpWjiiq1E/zhkYw92RsYTTXkNci2DIhl4bksm8kn7htG1QbogvCmNb5JKxcqV/INOv2ZhQo22DWOCUszmHWBjPIvQsJFRIIaQyKbvHxcLqtVGBg9gCOYN/YrbqPBY6UOghBUrha8HOZ8l+4iH1pI0CKJCE/KrpF47oedU40cS0tpMJg5b6S9XvCKPwGfVAcoGXZUmKhS76iOOCryBUmEpm9I2F5YToohfVtpqNyrKWxyPwbLRto616xzehsaDUCyeeFa0BDkDZBmlJpjuSeuHsvTaq5iCOYFoDnFzWj4uFVY08XLqmINBYTtYdiYVxBVyQej/Ossb4vOpYIWgxqLYQHINT9CnYWWylWEjeoBwDCgLPYvfe0c8zvJnU3+N0IUC7IRig7OC8kXWAY1FsraELiiBvURtyCPuye1wsynuKWCW38axqCsfBaqWxgLPLAc9tBFHGSSYKROrvcSqI+nBWRaN8FcXKTIDUC0f9mV4JKKOQLJhBPEw9azk6yj2In42OxEIsgXoo22gYPRMuHqJQhroJTqOGsks1FmFrGD09+Art1/OsJkD6GwfDgRkuiyiBYwKkvsa5vRbKsxriGS+LPB0LXVNRRC8TJcUIitmTQyxER2NxJieE7SG2zpZAxCJoEXROotxcocKvJjM6knjuwY997GMHOQMvuOCCpn2OZe5BkzMYG5QBXdHYe98m4Q6XexDgggsuaHIG/vCHP2z6/FjmHpS8QXIGscGqKdx9b1MH+K3cg/vJ5XKHdMA899xz3HfffTz22GONNHrf+ta3+OAHP8jXvvY1uru7E3UPum01QsvBKAvt2ehkRs6PTqv6y1/+kokTJzJz5kw+85nPsGfPnsZnxzz3oFFIqFC+xqqCNVaFu+CCC/j3f/93NmzYwFe/+lUeeughFi1aRBhG03LHOvegX7NRgzZ2WWMPqsTCZyTeql588cWNv2fNmsXs2bOZMWMGv/zlLznvvPOS/roGh3IPqrKNZTS6pjAuDE4+TjrAJ598MuPHj2/4v45m7sH29vamF0B+p4Xbr9AB+K1CbWoy1+pRF+61115jz549jSSOxzr3oD1I1CBIFBGCt2sE+K1yD5bLZa6++mp+85vf8Morr7Bhwwb++q//mlNOOYWFCxcCxz73YFiAMA9hPTAVCY0AJ+oerFQqcv7558uECRPEcRzp6emRZcuWyY4dO5rKOJa5B0+84Sty0q1fkxNv+5r0fGetTLvlxsw9+Fbsdw9OW3sjupBHBQoVgtpb4+Wv/N/MPXhY6ilCrarC6Ve4ryVTbPqFIxLOrigKu4WWbcm44FI/HicquhOpAKwquHuTGVZKvXBYgliCyYHfCpXuZKLrp144q2xh1RSihWqnYteZmc8hFoXtGiuvME705OBNyC7VWDiDgq63B8aFUimZ6KKpr3FBQaHy0UQNBgbKyQTeS71wXgl0URopB8OBLGR3LMJCtOocIUra2Jc1DrEIiwalBV1T2BWwB5IpN/XCSc4gBlBERpEs+XY8dD7AGIMKNWLVVy4lQOqFM56F1lGr6heBZBrV9Avn7HLQOQuxIWgTPCuZclMvnNurUEVFmAe/zRC0HidzDm879Xua1NcAazdzD8bCuKBcEIfIIFJL5lpNv3A26PrCaauqEMk6wLEIiwJutMzLqiqoZavOY2FceVONA13OhItHXScdgFMGa0/25BALUwgxIqgwmh7M781a1XgYFa02d8DrADM1a1VjUXjNRhd0lH7FgfK0ZMpNvXANf4MlhEUhcLNgBrEwbpSY1uQgbDFond3jYiGWgA3GFrANViZcPMKioAqCcQ3KFshsl/EwFmhLUEbBgE1QyWa54lF3CypP4ZQV9GXdkfgYFXnyQ4XKQnbHQ9c0WkdmOL/NRI1EEuUmUsoYxqpG6+MAwvaQ3EnJzA+mXjjtR0v1lYniLHW39yVT7kgPOJx78I+dg/tfa9eubexzLHMPOuUoVahdUZghm33VZFLoJe4efLNrcPv27dxxxx0opbjoooua9jtWuQffHExUVTW9/W9T1vLDuQf/2Pnys5/9jHPPPZeTTz65afuxyj1Y6xJoF4wdTdYkFQf4qN7jdu7cyc9//nOWLl160GfHKveg324Ii1EuB2vQwt1+HMSP+7d/+zfa2tr4yEc+0rT9WOYelFwUrVB7itw+hfv6cTACfMcdd3DZZZeRzzc/5hzL3IO5jip+mIOqwh5StCW0XP+oCfe///u/bNmyhR//+MeH3fdo5h4s5j08q8oQeapDDs6kZBYWHrV73Pe+9z3OOusszjjjjMPuezRzD1Y9B8cOGTd+gNzpvez7wNDIfsghSNQ9uJ/+/n7uvvtuPvnJTx50/MaNG7ntttt44oknePnll7nrrruGzT2YlHuwur2F/n1FKlWXrpYK757+6ojLGJaRuubeyj24n3/5l3+RQqEgvb29Bx1/rHMPnvzF1XLS178m0797i7zznmvlvfcuz9yDb8V+9+DMK1YjHXmCghB0Bbi5fVnuwTiEOcAWlImeHGphtuo8FsYRtIoe9u0BTWAy4WKhPYUt0QiJ9hRhNcuSFIugVQiKQugAAk7lOHhyGAsYR6KgogbsqpDbnU0PxsK0hnh2SFDQGFdTU9nCwnioKOegyRtqnYJ0J/PkkHrhVNUCW0fBRV2TpV6Ji1iyf20hyjLohPJLpV44XdVYouv5BzWisyUQsbAHFTpUiAWiLTyddYBjoT2FVb9YtW8RmONg6HwsYGxQuWjRjVUjyz0Yl7DVYIqC9iE3pMjvzRqHWIStIboQYkKF9izoz2pcLFRVg6PAFryJAdUsaWM87EEN2sK4ghRC3HHZk0MstKdQ1Sh4cuhb+G1ZqxoLFURhM1R9hCSQTLhYGAdMLkr5LvUZ/SRIvXDKgPaif1WgEJONAI8I2e8iTChkd+prnMkJgRvNculaNPeQBKkXTnsKrVVU4+rxR5Ig9cKJJYR5IXQFyQmhn4XPiIdE9zdxBd3h0dXdn0ix6RdOR758yRlK7YPM7Nx5+GPiFZtujFN3EGrBDy12DbUmUm7q73HGFZQCfE25v0DZG59IuakXTpx6KgIBGbIw5WzoPB4CyteoEOwhhc5m8mOiojlpHSjsQUV+RzYCHI9Aoag/q9ZDPiZB6oVz+hVWPnpyMBYMdWWjI7FQoUI0hHnBGx9iJJl076kXTvvRk4PJCS2TBpmW304SuTBSL5xxAav+zBom199PvXBBq0E7UVCqal+OrdXORMpNrXD7XQi+PYi2QgiBAcXgbtX0+WhJrc/h5ZdfZsaMGYf8/NVXX+WEE04YdfmprXGdndEluW3bNkqlEnDAUfjss882kqeNltQKp3XUEJRKpYMcNFOnTm18Puryj+joP2Ey4UZJaoXL5XJce+21Tebf4baNltS2qkeb1Na4o00m3CjJhBslmXCjJBNulKROuDVr1tDT04PWGqUU48aN4+67727a5/3vf/9B0cQuv/zykX3REYVCGIOcccYZYlmW3HjjjfJf//VfMm3aNFFKycsvv9zY55xzzpFly5bJ9u3bG6+RRoVInXBz5syR5cuXN97v2LFDAPnUpz7V2HbOOefIP/7jPx7R96TqUvU8j02bNrFgwYLGtoGBKLTj888/37TvXXfdxfjx4zn99NNZtWoVlcrIsmCmanRk9+7dhGHYiPxljOGKK65g6tSpTcJceuml9PT00N3dzZNPPsnKlSvZsmUL99xzT/wvO6L6OsZ4/fXXBZBHHnlEREQuv/xy6enpkcsvv1zmzJlzyOM2bNgggLz44ouxvytVl+r48eOxLIudO3eyYsUK1q1bx4MPPkilUjlkFDCIookBvPjii/G/7Ij/m8cYZ599tsyaNUu6u7vl+eeflzAMZerUqbJmzZpDHvOrX/1KAHniiSdif0+qahxAR0cHTz31FIsXL2b79u0sWbKEgYEBLr74YgBeeuklbrzxRjZt2sQrr7zCvffey+LFi5k/fz6zZ8+O/0VJ/C+PJRgm0hggd955p4iIbNu2TebPny+dnZ2Sy+XklFNOkauvvnrE/bhsPG6UpO5SPVZkwo2STLhRkgk3SjLhRkkm3CjJhBslmXCjJBNulGTCjZJMuFHy/wHRIegPzCprgwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "#train and test data directory\n",
    "data_dir = output_path+\"train/\"\n",
    "test_data_dir = output_path+\"test/\"\n",
    "\n",
    "def npy_loader(path):\n",
    "    sample = torch.from_numpy(np.load(path))\n",
    "    return sample\n",
    "\n",
    "#load the train and test data\n",
    "dataset = DatasetFolder(\n",
    "    root=data_dir,\n",
    "    loader=npy_loader,\n",
    "    extensions=['.npy']\n",
    ")\n",
    "test_dataset = DatasetFolder(\n",
    "    root=test_data_dir,\n",
    "    loader=npy_loader,\n",
    "    extensions=['.npy']\n",
    ")\n",
    "\n",
    "img, label = dataset[0]\n",
    "\n",
    "print(img.shape,label)\n",
    "print(\"Follwing classes are there : \\n\",dataset.classes)\n",
    "\n",
    "\n",
    "def display_img(img,label):\n",
    "    print(f\"Label : {dataset.classes[label]}\")\n",
    "    plt.imshow(img.permute(0,1))\n",
    "\n",
    "#display the first image in the dataset\n",
    "display_img(*dataset[0])\n",
    "\n",
    "batch_size = 1\n",
    "val_size = 2\n",
    "train_size = len(dataset) - val_size \n",
    "\n",
    "train_data,val_data = random_split(dataset,[train_size,val_size])\n",
    "print(f\"Length of Train Data : {len(train_data)}\")\n",
    "print(f\"Length of Validation Data : {len(val_data)}\")\n",
    "\n",
    "#output\n",
    "#Length of Train Data : 12034\n",
    "#Length of Validation Data : 2000\n",
    "\n",
    "#load the train and validation into batches.\n",
    "train_dl = DataLoader(train_data, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "val_dl = DataLoader(val_data, batch_size*2, num_workers = 4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        images = torch.reshape(images, (-1, 1, 2000, 30))\n",
    "        out = self(images.double())                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        images = torch.reshape(images, (-1, 1, 2000, 30))\n",
    "        out = self(images.double())                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 2, kernel_size = 15, padding = 0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4,4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2,2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.double()\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history\n",
    "\n",
    "num_epochs = 5\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001\n",
    "model = EEGClassification()\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('thesis_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "343c8484fb7cc4d3717e305d494ac201a19ddc5efe49b8492f89894e079ff7f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
